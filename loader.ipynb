{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khoawawa/ArtDetective/blob/main/loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "394iUdvSWlFn",
        "outputId": "3cc33e11-0ad7-44bb-d6b8-39561fedee72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ArtDetective' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    !git clone https://github.com/Khoawawa/ArtDetective.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4_O2cPcUc05",
        "outputId": "70b8a385-117d-46f7-fcd5-e6701e48cde6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/alessandrasala79/ai-vs-human-generated-dataset\n",
            "License(s): apache-2.0\n",
            "Downloading ai-vs-human-generated-dataset.zip to /content/dataset\n",
            " 33% 3.20G/9.76G [00:44<20:09, 5.82MB/s]"
          ]
        }
      ],
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "    !kaggle datasets download -d alessandrasala79/ai-vs-human-generated-dataset -p /content/dataset --unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHZ8d4ZUn07w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZpD4RV9qXNz"
      },
      "outputs": [],
      "source": [
        "path = \"/content/dataset\" if \"google.colab\" in sys.modules else \"E:/Code/Python/ML/dataset/HumanvsAi\"\n",
        "TRAIN_CSV = path + '/train.csv'\n",
        "TEST_CSV = path + '/test.csv'\n",
        "DATA_DIR = path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DqDj8Ltq14F"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "train_df = train_df[['file_name','label']]\n",
        "train_df.columns = ['id','label']\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4XMtP6krO8O"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(TEST_CSV)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsBMHEgwrrad"
      },
      "outputs": [],
      "source": [
        "print('Train set: ', len(train_df))\n",
        "print('Test set: ', len(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji84mdDFr1l5"
      },
      "source": [
        "Check for completeness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIpHDJwVr0eC"
      },
      "outputs": [],
      "source": [
        "print(\"Train null counts: \")\n",
        "print(train_df.isnull().sum())\n",
        "print(\"Test null counts: \")\n",
        "print(test_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zqfaSX9tIpr"
      },
      "source": [
        "Check for file existence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MHvrmsItClc"
      },
      "outputs": [],
      "source": [
        "def check_file_existence(df):\n",
        "  missing = []\n",
        "  for fname in df['id']:\n",
        "    if not os.path.isfile(os.path.join(DATA_DIR, fname)):\n",
        "      missing.append(fname)\n",
        "  return missing\n",
        "train_missing = check_file_existence(train_df)\n",
        "test_missing = check_file_existence(test_df)\n",
        "\n",
        "print(f'Missing train: {len(train_missing)}/{len(train_df)}')\n",
        "print(f'Missing test: {len(test_missing)}/{len(test_df)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w6Nx14BellP"
      },
      "source": [
        "MERGING FULL_FILE PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBePli8RepZ1"
      },
      "outputs": [],
      "source": [
        "train_df['id'] = train_df['id'].apply(lambda x: os.path.join(DATA_DIR, x))\n",
        "test_df['id'] = test_df['id'].apply(lambda x: os.path.join(DATA_DIR, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxcpM2crRufN"
      },
      "outputs": [],
      "source": [
        "train_df['pair_id'] = train_df.index //2\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIoyEoi-X8AJ"
      },
      "source": [
        "Removing duplicate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oCJD2jCcYme"
      },
      "outputs": [],
      "source": [
        "# Class balance\n",
        "label_counts = train_df[\"label\"].value_counts()\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=label_counts.index, y=label_counts.values)\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAVqsppahkkG"
      },
      "outputs": [],
      "source": [
        "pair_violations = sum(train_df['label'].diff()[1::2]!= -1) # think of it as if there are 2 of the same labels next to each other it would be 0\n",
        "print(f'Pairing violations: {pair_violations}/{len(train_df)//2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5r6m0h_j4hE"
      },
      "outputs": [],
      "source": [
        "# Pair completeness check\n",
        "pair_sizes = train_df.groupby(\"pair_id\")[\"id\"].count().value_counts()\n",
        "print(\"\\nPair size distribution:\")\n",
        "print(pair_sizes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf24aOXEmfVM"
      },
      "source": [
        "--> K fold cross validation and Binary Cross-Entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLg_dMqJX3n1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJRLrAaGX2yk"
      },
      "outputs": [],
      "source": [
        "def analyze_image_metadata(train_df, sample_size=10000):\n",
        "    print(\"=== Image Metadata Analysis ===\")\n",
        "\n",
        "    # Sampling\n",
        "    sample = train_df.sample(sample_size, random_state=42)\n",
        "    metadata = []\n",
        "\n",
        "    for _, row in tqdm(sample.iterrows(), total=sample_size, desc=\"Processing images\"):\n",
        "        img_path = row['id']\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                width, height = img.size\n",
        "                mode = img.mode\n",
        "                format_ = img.format\n",
        "        except:\n",
        "            width, height, mode, format_ = (None,)*4\n",
        "\n",
        "        metadata.append({\n",
        "            \"width\": width,\n",
        "            \"height\": height,\n",
        "            \"channels\": len(mode) if mode else None,\n",
        "            \"format\": format_\n",
        "        })\n",
        "\n",
        "    meta_df = pd.DataFrame(metadata)\n",
        "\n",
        "    # Dimension analysis\n",
        "    print(\"\\n=== Dimension Statistics ===\")\n",
        "    print(f\"Average dimensions: {meta_df['width'].mean():.1f}x{meta_df['height'].mean():.1f}\")\n",
        "    print(\"Dimension distribution:\")\n",
        "    print(meta_df[['width', 'height']].describe())\n",
        "\n",
        "    # Format distribution\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    meta_df['format'].value_counts().plot(kind='bar')\n",
        "    plt.title(\"Image Format Distribution\")\n",
        "    plt.show()\n",
        "\n",
        "    # Channel analysis\n",
        "    channel_dist = meta_df['channels'].value_counts()\n",
        "    print(\"\\nChannel distribution:\")\n",
        "    print(channel_dist)\n",
        "\n",
        "    return meta_df\n",
        "\n",
        "meta_df = analyze_image_metadata(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJPc7qo9lti8"
      },
      "outputs": [],
      "source": [
        "def visualize_image_samples(train_df, n_samples=5):\n",
        "    print(\"=== Visual Pattern Analysis ===\")\n",
        "\n",
        "    def plot_comparison(label, title):\n",
        "        plt.figure(figsize=(15, 3))\n",
        "        samples = train_df[train_df['label'] == label].sample(n_samples, random_state=42)\n",
        "        for i, (_, row) in enumerate(samples.iterrows()):\n",
        "            img_path = row['id']\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "                plt.subplot(1, n_samples, i+1)\n",
        "                plt.imshow(img)\n",
        "                plt.title(f\"Label {label}\\n{img.size[0]}x{img.size[1]}\")\n",
        "                plt.axis('off')\n",
        "            except:\n",
        "                plt.title(\"Failed to load\")\n",
        "        plt.suptitle(title)\n",
        "        plt.show()\n",
        "\n",
        "    # Compare AI vs Human\n",
        "    plot_comparison(1, \"AI-Generated Samples\")\n",
        "    plot_comparison(0, \"Human-Created Samples\")\n",
        "\n",
        "visualize_image_samples(train_df,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aff0I-w8TLgJ"
      },
      "outputs": [],
      "source": [
        "def visualize_gray_scale_image_samples(train_df, n_samples=5):\n",
        "    print(\"=== Visual Pattern Analysis ===\")\n",
        "\n",
        "    def load_and_convert_to_gray(img_path):\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "        return img\n",
        "\n",
        "    def plot_comparison(label, title):\n",
        "        plt.figure(figsize=(15, 3))\n",
        "        samples = train_df[train_df['label'] == label].sample(n_samples, random_state=42)\n",
        "        for i, (_, row) in enumerate(samples.iterrows()):\n",
        "            img_path = row['id']\n",
        "            try:\n",
        "                img = load_and_convert_to_gray(img_path)\n",
        "                plt.subplot(1, n_samples, i + 1)\n",
        "                plt.imshow(img, cmap='gray')  # Ensure grayscale display\n",
        "                plt.title(f\"Label {label}\\n{img.shape[1]}x{img.shape[0]}\")\n",
        "                plt.axis('off')\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img_path}: {e}\")\n",
        "                plt.title(\"Failed to load\")\n",
        "        plt.suptitle(title)\n",
        "        plt.show()\n",
        "\n",
        "    # Compare AI vs Human\n",
        "    plot_comparison(1, \"AI-Generated Samples\")\n",
        "    plot_comparison(0, \"Human-Created Samples\")\n",
        "\n",
        "# visualize_gray_scale_image_samples(train_df, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzSCxTM1Xxco"
      },
      "outputs": [],
      "source": [
        "def plot_pixel_intensity_side_by_side(img1_path,img2_path,title1 = \"AI-Generated Samples\", title2 = \"Human-Created Samples\"):\n",
        "  img1 = cv2.imread(img1_path,cv2.IMREAD_GRAYSCALE)\n",
        "  img2 = cv2.imread(img2_path,cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "  fig, axes = plt.subplots(2, 2, figsize=(12, 10))  # 1 row, 2 columns\n",
        "  # Display Images\n",
        "  axes[0, 0].imshow(img1, cmap='gray')\n",
        "  axes[0, 0].set_title(title1)\n",
        "  axes[0, 0].axis('off')\n",
        "\n",
        "  axes[0, 1].imshow(img2, cmap='gray')\n",
        "  axes[0, 1].set_title(title2)\n",
        "  axes[0, 1].axis('off')\n",
        "\n",
        "  axes[1,0].hist(img1.ravel(), bins=256, color=\"gray\", alpha=0.7)\n",
        "  axes[1,0].set_xlabel(\"Pixel Intensity\")\n",
        "  axes[1,0].set_ylabel(\"Count\")\n",
        "  axes[1,0].set_title(f\"{title1} - Pixel Intensity\")\n",
        "\n",
        "  axes[1,1].hist(img2.ravel(), bins=256, color=\"gray\", alpha=0.7)\n",
        "  axes[1,1].set_xlabel(\"Pixel Intensity\")\n",
        "  axes[1,1].set_ylabel(\"Count\")\n",
        "  axes[1,1].set_title(f\"{title2} - Pixel Intensity\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "sample_ai = train_df[train_df['label'] == 1]['id'].sample(1, random_state=42).values[0]\n",
        "sample_human = train_df[train_df['label'] == 0]['id'].sample(1, random_state=42).values[0]\n",
        "\n",
        "plot_pixel_intensity_side_by_side(sample_ai,sample_human)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ActhMd2g-WP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import AdamW, Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.transforms import InterpolationMode\n",
        "import torchvision.models as models\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E772LXoiUxr"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (224,224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9znav1YgyCn"
      },
      "outputs": [],
      "source": [
        "train_transform = T.Compose([\n",
        "    T.Resize(IMG_SIZE, interpolation=InterpolationMode.BICUBIC),\n",
        "    T.RandomResizedCrop(IMG_SIZE),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomVerticalFlip(),\n",
        "    T.RandomRotation(20),\n",
        "    T.GaussianBlur(kernel_size=(7, 13), sigma=(0.1, 1.0)),\n",
        "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtxqP8XnkVUE"
      },
      "outputs": [],
      "source": [
        "test_transforms = T.Compose([\n",
        "    T.Resize(IMG_SIZE, interpolation=InterpolationMode.BICUBIC),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqgYIq5cUWlQ"
      },
      "outputs": [],
      "source": [
        "print(test_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRbKKy6CTRdu"
      },
      "outputs": [],
      "source": [
        "df_train, df_test = train_test_split(train_df[:5000], test_size=0.2, stratify=train_df.iloc[:5000, 1],random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "kVWUpvceKX16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "model = timm.create_model(\"vit_base_patch16_224\", pretrained=True, num_classes=2)  # 2 classes: AI vs. Human\n",
        "model.eval()  # Set model to evaluation mode\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6hrsAl5aKnKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, root_dir, transform=None):\n",
        "        self.data = dataframe\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])  # Image filename\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        label = int(self.data.iloc[idx, 1])  # Label\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "nRozUnbPK66k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(df_train, DATA_DIR, transform=train_transform)\n",
        "test_dataset = CustomDataset(df_test, DATA_DIR, transform=test_transforms)"
      ],
      "metadata": {
        "id": "hkbxxhBKOKmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "YiK6QJMnPFII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}, Acc: {correct/total:.4f}\")\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), \"fine_tuned_vit.pth\")\n"
      ],
      "metadata": {
        "id": "Cvy3GAbZRgkX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}